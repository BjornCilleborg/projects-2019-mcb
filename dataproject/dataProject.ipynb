{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2010-06-29     100.000000\n",
      "2010-06-30      99.748851\n",
      "2010-07-01      91.921305\n",
      "2010-07-02      80.368360\n",
      "2010-07-06      67.434077\n",
      "2010-07-07      66.136461\n",
      "2010-07-08      73.084971\n",
      "2010-07-09      72.833822\n",
      "2010-07-12      71.368772\n",
      "2010-07-13      75.931351\n",
      "2010-07-14      83.047303\n",
      "2010-07-15      83.256592\n",
      "2010-07-16      86.395981\n",
      "2010-07-19      91.712015\n",
      "2010-07-20      84.972791\n",
      "2010-07-21      84.637923\n",
      "2010-07-22      87.902890\n",
      "2010-07-23      89.116791\n",
      "2010-07-26      87.693601\n",
      "2010-07-27      86.019254\n",
      "2010-07-28      86.730849\n",
      "2010-07-29      85.182088\n",
      "2010-07-30      83.465890\n",
      "2010-08-02      87.568023\n",
      "2010-08-03      91.879453\n",
      "2010-08-04      88.991213\n",
      "2010-08-05      85.600675\n",
      "2010-08-06      82.000840\n",
      "2010-08-09      82.042699\n",
      "2010-08-10      79.656765\n",
      "                 ...     \n",
      "2019-02-21    1219.045703\n",
      "2019-02-22    1233.612386\n",
      "2019-02-25    1250.606934\n",
      "2019-02-26    1246.797794\n",
      "2019-02-27    1317.454995\n",
      "2019-02-28    1338.970335\n",
      "2019-03-01    1233.947326\n",
      "2019-03-04    1194.474645\n",
      "2019-03-05    1157.555528\n",
      "2019-03-06    1156.299696\n",
      "2019-03-07    1157.764769\n",
      "2019-03-08    1189.368028\n",
      "2019-03-11    1217.748099\n",
      "2019-03-12    1186.102941\n",
      "2019-03-13    1209.543737\n",
      "2019-03-14    1213.729589\n",
      "2019-03-15    1152.909166\n",
      "2019-03-18    1128.045195\n",
      "2019-03-19    1119.589820\n",
      "2019-03-20    1145.249113\n",
      "2019-03-21    1147.007099\n",
      "2019-03-22    1107.283405\n",
      "2019-03-25    1090.079615\n",
      "2019-03-26    1120.845525\n",
      "2019-03-27    1150.397629\n",
      "2019-03-28    1166.262044\n",
      "2019-03-29    1171.452459\n",
      "2019-04-01    1210.464630\n",
      "2019-04-02    1196.651370\n",
      "2019-04-03    1231.477688\n",
      "Name: Adj Close, Length: 2206, dtype: float64\n",
      "                 Open       High\n",
      "Date                            \n",
      "2010-06-29  19.000000  25.000000\n",
      "2010-06-30  25.790001  30.420000\n",
      "2010-07-01  25.000000  25.920000\n",
      "2010-07-02  23.000000  23.100000\n",
      "2010-07-06  20.000000  20.000000\n",
      "2010-07-07  16.400000  16.629999\n",
      "2010-07-08  16.139999  17.520000\n",
      "2010-07-09  17.580000  17.900000\n",
      "2010-07-12  17.950001  18.070000\n",
      "2010-07-13  17.389999  18.639999\n",
      "2010-07-14  17.940001  20.150000\n",
      "2010-07-15  19.940001  21.500000\n",
      "2010-07-16  20.700001  21.299999\n",
      "2010-07-19  21.370001  22.250000\n",
      "2010-07-20  21.850000  21.850000\n",
      "2010-07-21  20.660000  20.900000\n",
      "2010-07-22  20.500000  21.250000\n",
      "2010-07-23  21.190001  21.559999\n",
      "2010-07-26  21.500000  21.500000\n",
      "2010-07-27  20.910000  21.180000\n"
     ]
    }
   ],
   "source": [
    "%load Dataproject.py\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "#First pass\n",
    "\"\"\"\n",
    "write this in the Terminal:\n",
    "pip install https://github.com/matplotlib/mpl_finance/archive/master.zip\n",
    "\n",
    "And this:\n",
    "conda install -c anaconda pandas-datareader\n",
    "\n",
    "When asked:\n",
    "The following packages will be SUPERSEDED by a higher-priority channel:\n",
    "\n",
    "  ca-certificates                                 pkgs/main --> anaconda\n",
    "  certifi                                         pkgs/main --> anaconda\n",
    "  openssl                                         pkgs/main --> anaconda\n",
    "  qt                                              pkgs/main --> anaconda\n",
    "Proceed ([y]/n)?\n",
    "\n",
    "Press y\n",
    "\"\"\"\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from mpl_finance import candlestick_ohlc\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "import numpy as np\n",
    "import bs4 as bs\n",
    "import pickle\n",
    "import requests\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.stats import norm # normal distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "style.use(\"ggplot\")\n",
    "\n",
    "\n",
    "#Tesla\n",
    "start = dt.datetime(2000,1,1)\n",
    "end = (2016,12,31)\n",
    "\n",
    "Stock = web.DataReader(\"TSLA\", data_source = \"yahoo\", start=\"1/1/2010\")\n",
    "df_helper = Stock[\"Adj Close\"]\n",
    "df_index = df_helper.div(df_helper[0])*100\n",
    "\n",
    "\n",
    "print(df_index)\n",
    "\n",
    "#Tesla.to_excel(\"TSLA.xls\") #Laver en Excel fil\n",
    "Stock.to_csv(\"Stock.csv\")\n",
    "\n",
    "#Indlæs en csv fil, og lav datetime index\n",
    "csv = pd.read_csv(\"Stock.csv\", parse_dates=True, index_col=0)\n",
    "csv.head(100) #Helt det samme som før, bare en anden metode\n",
    "\n",
    "csv['Adj Close'].plot()\n",
    "csv['Open'].plot()\n",
    "\n",
    "print(csv[[\"Open\", \"High\"]].head(20))\n",
    "\n",
    "csv[\"100ma\"] = csv[\"Adj Close\"].rolling(window=100, min_periods=0).mean()    #100 moving average - pris idag, og 99 forrige priser.\n",
    "\n",
    "csv.head(10)\n",
    "csv.tail(10)\n",
    "\n",
    "#Multiple plots\n",
    "\n",
    "ax1 = plt.subplot2grid((6,1), (0,0), rowspan= 5, colspan=1)  #6 rows, 1 column. Starts at (0,0) and spans over|\n",
    "ax2 = plt.subplot2grid((6,1), (5,0), rowspan= 5, colspan=1, sharex = ax1)\n",
    "\n",
    "ax1.plot(csv.index, csv[\"Adj Close\"])\n",
    "ax1.plot(csv.index, csv[\"100ma\"])\n",
    "ax2.plot(csv.index, csv[\"Volume\"])\n",
    "\n",
    "#Resampling data\n",
    "Stock_ohlc = csv[\"Adj Close\"].resample(\"10D\").ohlc() #Ohlc = Open, high, low, close. 10D = 10 days\n",
    "Stock_volume = csv[\"Volume\"].resample(\"10D\").sum()\n",
    "\n",
    "Stock_ohlc.head()\n",
    "\n",
    "Stock_ohlc.reset_index(inplace=True)\n",
    "\n",
    "#Convert to mdates and candlestick\n",
    "Stock_ohlc = csv[\"Adj Close\"].resample(\"10D\").ohlc() #Ohlc = Open, high, low, close. 10D = 10 days\n",
    "Stock_volume = csv[\"Volume\"].resample(\"10D\").sum()\n",
    "Stock_ohlc.reset_index(inplace=True)\n",
    "\n",
    "Stock_ohlc[\"Date\"] = Stock_ohlc[\"Date\"].map(mdates.date2num)\n",
    "\n",
    "ax1 = plt.subplot2grid((6,1), (0,0), rowspan= 5, colspan=1)  \n",
    "ax2 = plt.subplot2grid((6,1), (5,0), rowspan= 5, colspan=1, sharex = ax1)\n",
    "ax1.xaxis_date()\n",
    "\n",
    "candlestick_ohlc(ax1,Stock_ohlc.values, width=2, colorup=\"g\")\n",
    "ax2.fill_between(Stock_volume.index.map(mdates.date2num), Stock_volume.values, 0)\n",
    "plt.show() #Candlestick and volume on the lower graph\n",
    "\n",
    "\n",
    "#Automating S&P500 - From Yahoo Finance - Close price adjusted for splits, and Adj. Close price is adjusted for both dividends and splits.\n",
    "def save_sp500_tickers():\n",
    "    resp = requests.get(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")\n",
    "    soup = bs.BeautifulSoup(resp.text, \"lxml\")\n",
    "    table = soup.find(\"table\", {\"class\": \"wikitable sortable\"})\n",
    "    tickers = []\n",
    "    for row in table.findAll(\"tr\")[1:]:\n",
    "        ticker = row.findAll(\"td\")[1].text.replace(\".\",\"-\")\n",
    "        tickers.append(ticker)\n",
    "\n",
    "    with open(\"sp500tickers.pickle\", \"wb\") as f:\n",
    "        pickle.dump(tickers, f)\n",
    "    \n",
    "        print(tickers)\n",
    "\n",
    "        return(tickers)\n",
    "    \n",
    "\n",
    "save_sp500_tickers()\n",
    "\n",
    "\n",
    "#Getting data from Yahoo\n",
    "def data_yahoo(reload_sp500=False):\n",
    "    if reload_sp500:\n",
    "        tickers = save_sp500_tickers()\n",
    "    else:\n",
    "        with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "            tickers = pickle.load(f)\n",
    "    if not os.path.exists('stock_dfs'):\n",
    "        os.makedirs('stock_dfs')\n",
    "\n",
    "    start = dt.datetime(2000, 1, 1)\n",
    "    end = dt.datetime.now()\n",
    "    for ticker in tickers:\n",
    "        # just in case your connection breaks, we'd like to save our progress!\n",
    "        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n",
    "            df = web.DataReader(ticker, 'yahoo', start, end)\n",
    "            df.to_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        else:\n",
    "            print('Already have {}'.format(ticker))\n",
    "\n",
    "data_yahoo()\n",
    "\n",
    "\n",
    "def compile_data():\n",
    "    with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "        tickers = pickle.load(f)\n",
    "\n",
    "    main_df = pd.DataFrame()\n",
    "\n",
    "    #Iterating though all DFs\n",
    "\n",
    "    for count, ticker in enumerate(tickers):\n",
    "        df = pd.read_csv(\"stock_dfs/{}.csv\".format(ticker))\n",
    "        df.set_index(\"Date\", inplace=True)\n",
    "        df.rename(columns = {\"Adj Close\": ticker}, inplace=True) #Adj Close takes the categories place in the column - Simple rename\n",
    "        df.drop([\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"],1, inplace=True)\n",
    "        df = df.divide(df.iloc[0])*100\n",
    "\n",
    "        if main_df.empty:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df = main_df.join(df, how=\"outer\")\n",
    "        \n",
    "        if count % 10 == 0: #Only print #10, #20, #30, etc.\n",
    "            print(count)\n",
    "    print(main_df.head())\n",
    "    main_df.to_csv(\"sp500_joined_adj_closes.csv\")\n",
    "\n",
    "compile_data()\n",
    "\n",
    "df_stocks = pd.read_csv(\"sp500_joined_adj_closes.csv\")\n",
    "df_stocks.set_index(\"Date\", inplace=True)\n",
    "\n",
    "print(df_stocks)\n",
    "\n",
    "#Get sp500 index data\n",
    "\n",
    "Index_data = web.DataReader(\"^GSPC\", data_source=\"yahoo\", start=\"1,1,2000\")\n",
    "Index_data.to_csv(\"IndexData.csv\")\n",
    "\n",
    "df_index_data = pd.read_csv(\"IndexData.csv\", parse_dates=True)\n",
    "df_index_data.set_index(\"Date\", inplace=True)\n",
    "df_index_data.rename(columns = {\"Adj Close\": \"S&P500\"}, inplace=True)\n",
    "\n",
    "df_index_data_new = df_index_data[\"S&P500\"]\n",
    "print(df_index_data_new)\n",
    "\n",
    "df_index_data_new = df_index_data_new/df_index_data_new[0]*100\n",
    "print(df_index_data_new)\n",
    "df_index_data_new.plot()\n",
    "\n",
    "df_final = df_stocks.join(df_index_data_new, how=\"left\")\n",
    "print(df_final)\n",
    "\n",
    "#Widget/plot\n",
    "\n",
    "with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "    tickers = pickle.load(f)\n",
    "\n",
    "\n",
    "df_final[\"ATVI\"].plot(legend=True)\n",
    "\n",
    "\n",
    "\n",
    "# Ticker = widgets.textbox(\n",
    "#     description = \"Ticker:\", \n",
    "#     value = \"Firms\", \n",
    "#     options=tickers.unique().tolist()\n",
    "# )\n",
    "\n",
    "# def validate():\n",
    "#     if Ticker.value in df_final.unique():\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "# trace1 = go.plot(x=df_final(tickers), opacity = 1, name = tickers)\n",
    "\n",
    "# def response(change):\n",
    "\n",
    "\n",
    "widgets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def Figure_hist_Pct_Change(column = tickers):\n",
    "\n",
    "#     df_AdjClosed = pd.read_csv(\"sp500_joined_adj_closes.csv\")\n",
    "#     df_AdjClosed.set_index('Date', inplace=True)\n",
    "#     df_AdjClosed = df_AdjClosed.pct_change()\n",
    "\n",
    "#     with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "#         tickers = pickle.load(f)\n",
    "\n",
    "# Figure_hist_Pct_Change()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %load Dataproject.py\n",
    "#First pass\n",
    "\"\"\"\n",
    "write this in the Terminal:\n",
    "pip install https://github.com/matplotlib/mpl_finance/archive/master.zip\n",
    "\n",
    "And this:\n",
    "conda install -c anaconda pandas-datareader\n",
    "\n",
    "When asked:\n",
    "The following packages will be SUPERSEDED by a higher-priority channel:\n",
    "\n",
    "  ca-certificates                                 pkgs/main --> anaconda\n",
    "  certifi                                         pkgs/main --> anaconda\n",
    "  openssl                                         pkgs/main --> anaconda\n",
    "  qt                                              pkgs/main --> anaconda\n",
    "Proceed ([y]/n)?\n",
    "\n",
    "Press y\n",
    "\"\"\"\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from mpl_finance import candlestick_ohlc\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "import numpy as np\n",
    "import bs4 as bs\n",
    "import pickle\n",
    "import requests\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.stats import norm # normal distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "style.use(\"ggplot\")\n",
    "\n",
    "\n",
    "#Tesla\n",
    "start = dt.datetime(2000,1,1)\n",
    "end = (2016,12,31)\n",
    "\n",
    "Stock = web.DataReader(\"TSLA\", data_source = \"yahoo\", start=\"1/1/2010\")\n",
    "df_helper = Stock[\"Adj Close\"]\n",
    "df_index = df_helper.div(df_helper[0])*100\n",
    "\n",
    "\n",
    "print(df_index)\n",
    "\n",
    "#Tesla.to_excel(\"TSLA.xls\") #Laver en Excel fil\n",
    "Stock.to_csv(\"Stock.csv\")\n",
    "\n",
    "#Indlæs en csv fil, og lav datetime index\n",
    "csv = pd.read_csv(\"Stock.csv\", parse_dates=True, index_col=0)\n",
    "csv.head(100) #Helt det samme som før, bare en anden metode\n",
    "\n",
    "csv['Adj Close'].plot()\n",
    "csv['Open'].plot()\n",
    "\n",
    "print(csv[[\"Open\", \"High\"]].head(20))\n",
    "\n",
    "csv[\"100ma\"] = csv[\"Adj Close\"].rolling(window=100, min_periods=0).mean()    #100 moving average - pris idag, og 99 forrige priser.\n",
    "\n",
    "csv.head(10)\n",
    "csv.tail(10)\n",
    "\n",
    "#Multiple plots\n",
    "\n",
    "ax1 = plt.subplot2grid((6,1), (0,0), rowspan= 5, colspan=1)  #6 rows, 1 column. Starts at (0,0) and spans over|\n",
    "ax2 = plt.subplot2grid((6,1), (5,0), rowspan= 5, colspan=1, sharex = ax1)\n",
    "\n",
    "ax1.plot(csv.index, csv[\"Adj Close\"])\n",
    "ax1.plot(csv.index, csv[\"100ma\"])\n",
    "ax2.plot(csv.index, csv[\"Volume\"])\n",
    "\n",
    "#Resampling data\n",
    "Stock_ohlc = csv[\"Adj Close\"].resample(\"10D\").ohlc() #Ohlc = Open, high, low, close. 10D = 10 days\n",
    "Stock_volume = csv[\"Volume\"].resample(\"10D\").sum()\n",
    "\n",
    "Stock_ohlc.head()\n",
    "\n",
    "Stock_ohlc.reset_index(inplace=True)\n",
    "\n",
    "#Convert to mdates and candlestick\n",
    "Stock_ohlc = csv[\"Adj Close\"].resample(\"10D\").ohlc() #Ohlc = Open, high, low, close. 10D = 10 days\n",
    "Stock_volume = csv[\"Volume\"].resample(\"10D\").sum()\n",
    "Stock_ohlc.reset_index(inplace=True)\n",
    "\n",
    "Stock_ohlc[\"Date\"] = Stock_ohlc[\"Date\"].map(mdates.date2num)\n",
    "\n",
    "ax1 = plt.subplot2grid((6,1), (0,0), rowspan= 5, colspan=1)  \n",
    "ax2 = plt.subplot2grid((6,1), (5,0), rowspan= 5, colspan=1, sharex = ax1)\n",
    "ax1.xaxis_date()\n",
    "\n",
    "candlestick_ohlc(ax1,Stock_ohlc.values, width=2, colorup=\"g\")\n",
    "ax2.fill_between(Stock_volume.index.map(mdates.date2num), Stock_volume.values, 0)\n",
    "plt.show() #Candlestick and volume on the lower graph\n",
    "\n",
    "\n",
    "#Automating S&P500 - From Yahoo Finance - Close price adjusted for splits, and Adj. Close price is adjusted for both dividends and splits.\n",
    "def save_sp500_tickers():\n",
    "    resp = requests.get(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")\n",
    "    soup = bs.BeautifulSoup(resp.text, \"lxml\")\n",
    "    table = soup.find(\"table\", {\"class\": \"wikitable sortable\"})\n",
    "    tickers = []\n",
    "    for row in table.findAll(\"tr\")[1:]:\n",
    "        ticker = row.findAll(\"td\")[1].text.replace(\".\",\"-\")\n",
    "        tickers.append(ticker)\n",
    "\n",
    "    with open(\"sp500tickers.pickle\", \"wb\") as f:\n",
    "        pickle.dump(tickers, f)\n",
    "    \n",
    "        print(tickers)\n",
    "\n",
    "        return(tickers)\n",
    "    \n",
    "\n",
    "save_sp500_tickers()\n",
    "\n",
    "\n",
    "# def save_sp500_names():\n",
    "#     resp_names = requests.get(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")\n",
    "#     soup_names = bs.BeautifulSoup(resp_names.text, \"lxml\")\n",
    "#     table_names = soup_names.find(\"table\", {\"class\": \"wikitable sortable\"})\n",
    "#     names = []\n",
    "#     for row in table_names.findAll('tr')[1:]:\n",
    "#         name = row.findAll('td')[0].text.replace('.','-')\n",
    "#         names.append(name)\n",
    "#         df_names = pd.DataFrame(names)\n",
    "#         df_names.to_csv(\"sp500names.csv\")\n",
    "        \n",
    "#     with open(\"sp500names.pickle\", \"wb\") as n:\n",
    "#         pickle.dump(names, n)\n",
    "    \n",
    "#         print(names)\n",
    "\n",
    "#         return(names)\n",
    "    \n",
    "# save_sp500_names()\n",
    "\n",
    "# df_names = pd.read_csv(\"sp500names.csv\")\n",
    "\n",
    "# def sp500_GICS_sectors():\n",
    "#     resp_gics = requests.get(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")\n",
    "#     soup_gics = bs.BeautifulSoup(resp_gics.text, \"lxml\")\n",
    "#     table_gics = soup_gics.find(\"table\", {\"class\": \"wikitable sortable\"})\n",
    "#     gics_sectors = []\n",
    "#     for row in table_gics.findAll(\"tr\")[1:]:\n",
    "#         gics_sector = row.findAll(\"td\")[3].text.replace(\".\",\"-\")\n",
    "#         gics_sectors.append(gics_sector)\n",
    "#         df_sectors = pd.DataFrame(gics_sectors)\n",
    "#         df_sectors.to_csv(\"sp500sectors.csv\")\n",
    "\n",
    "#     with open(\"sp500GICS.pickle\",\"wb\") as g:\n",
    "#         pickle.dump(gics_sectors, g)\n",
    "\n",
    "#         print(gics_sectors)\n",
    "\n",
    "#         return(gics_sectors)\n",
    "\n",
    "# sp500_GICS_sectors()\n",
    "\n",
    "# df_sectors = pd.read_csv(\"sp500sectors.csv\")\n",
    "\n",
    "#Getting data from Yahoo\n",
    "def data_yahoo(reload_sp500=False):\n",
    "    if reload_sp500:\n",
    "        tickers = save_sp500_tickers()\n",
    "    else:\n",
    "        with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "            tickers = pickle.load(f)\n",
    "    if not os.path.exists('stock_dfs'):\n",
    "        os.makedirs('stock_dfs')\n",
    "\n",
    "    start = dt.datetime(2000, 1, 1)\n",
    "    end = dt.datetime.now()\n",
    "    for ticker in tickers:\n",
    "        # just in case your connection breaks, we'd like to save our progress!\n",
    "        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n",
    "            df = web.DataReader(ticker, 'yahoo', start, end)\n",
    "            df.to_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        else:\n",
    "            print('Already have {}'.format(ticker))\n",
    "\n",
    "data_yahoo()\n",
    "\n",
    "\n",
    "def compile_data():\n",
    "    with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "        tickers = pickle.load(f)\n",
    "\n",
    "    main_df = pd.DataFrame()\n",
    "\n",
    "    #Iterating though all DFs\n",
    "\n",
    "    for count, ticker in enumerate(tickers):\n",
    "        df = pd.read_csv(\"stock_dfs/{}.csv\".format(ticker))\n",
    "        df.set_index(\"Date\", inplace=True)\n",
    "        df.rename(columns = {\"Adj Close\": ticker}, inplace=True) #Adj Close takes the categories place in the column - Simple rename\n",
    "        df.drop([\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"],1, inplace=True)\n",
    "        df = df.divide(df.iloc[0])*100\n",
    "\n",
    "        if main_df.empty:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df = main_df.join(df, how=\"outer\")\n",
    "        \n",
    "        if count % 10 == 0: #Only print #10, #20, #30, etc.\n",
    "            print(count)\n",
    "    print(main_df.head())\n",
    "    main_df.to_csv(\"sp500_joined_adj_closes.csv\")\n",
    "\n",
    "compile_data()\n",
    "\n",
    "df_stocks = pd.read_csv(\"sp500_joined_adj_closes.csv\")\n",
    "df_stocks.set_index(\"Date\", inplace=True)\n",
    "\n",
    "print(df_stocks)\n",
    "\n",
    "#Get sp500 index data\n",
    "\n",
    "Index_data = web.DataReader(\"^GSPC\", data_source=\"yahoo\", start=\"1,1,2000\")\n",
    "Index_data.to_csv(\"IndexData.csv\")\n",
    "\n",
    "df_index_data = pd.read_csv(\"IndexData.csv\", parse_dates=True)\n",
    "df_index_data.set_index(\"Date\", inplace=True)\n",
    "df_index_data.rename(columns = {\"Adj Close\": \"S&P500\"}, inplace=True)\n",
    "\n",
    "df_index_data_new = df_index_data[\"S&P500\"]\n",
    "print(df_index_data_new)\n",
    "\n",
    "df_index_data_new = df_index_data_new/df_index_data_new[0]*100\n",
    "print(df_index_data_new)\n",
    "df_index_data_new.plot()\n",
    "\n",
    "df_final = df_stocks.join(df_index_data_new, how=\"left\")\n",
    "print(df_final)\n",
    "\n",
    "#Widget/plot\n",
    "\n",
    "with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "    tickers = pickle.load(f)\n",
    "\n",
    "\n",
    "df_final[\"ATVI\"].plot(legend=True)\n",
    "\n",
    "\n",
    "\n",
    "# Ticker = widgets.textbox(\n",
    "#     description = \"Ticker:\", \n",
    "#     value = \"Firms\", \n",
    "#     options=tickers.unique().tolist()\n",
    "# )\n",
    "\n",
    "# def validate():\n",
    "#     if Ticker.value in df_final.unique():\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "# trace1 = go.plot(x=df_final(tickers), opacity = 1, name = tickers)\n",
    "\n",
    "# def response(change):\n",
    "\n",
    "\n",
    "widgets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def Figure_hist_Pct_Change(column = tickers):\n",
    "\n",
    "#     df_AdjClosed = pd.read_csv(\"sp500_joined_adj_closes.csv\")\n",
    "#     df_AdjClosed.set_index('Date', inplace=True)\n",
    "#     df_AdjClosed = df_AdjClosed.pct_change()\n",
    "\n",
    "#     with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "#         tickers = pickle.load(f)\n",
    "\n",
    "# Figure_hist_Pct_Change()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MMM', 'ABT', 'ABBV', 'ABMD', 'ACN', 'ATVI', 'ADBE', 'AMD', 'AAP', 'AES', 'AMG', 'AFL', 'A', 'APD', 'AKAM', 'ALK', 'ALB', 'ARE', 'ALXN', 'ALGN', 'ALLE', 'AGN', 'ADS', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AEE', 'AAL', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'ABC', 'AME', 'AMGN', 'APH', 'APC', 'ADI', 'ANSS', 'ANTM', 'AON', 'AOS', 'APA', 'AIV', 'AAPL', 'AMAT', 'APTV', 'ADM', 'ARNC', 'ANET', 'AJG', 'AIZ', 'ATO', 'T', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'BHGE', 'BLL', 'BAC', 'BK', 'BAX', 'BBT', 'BDX', 'BRK-B', 'BBY', 'BIIB', 'BLK', 'HRB', 'BA', 'BKNG', 'BWA', 'BXP', 'BSX', 'BHF', 'BMY', 'AVGO', 'BR', 'BF-B', 'CHRW', 'COG', 'CDNS', 'CPB', 'COF', 'CPRI', 'CAH', 'KMX', 'CCL', 'CAT', 'CBOE', 'CBRE', 'CBS', 'CE', 'CELG', 'CNC', 'CNP', 'CTL', 'CERN', 'CF', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'XEC', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CTXS', 'CLX', 'CME', 'CMS', 'KO', 'CTSH', 'CL', 'CMCSA', 'CMA', 'CAG', 'CXO', 'COP', 'ED', 'STZ', 'COO', 'CPRT', 'GLW', 'COST', 'COTY', 'CCI', 'CSX', 'CMI', 'CVS', 'DHI', 'DHR', 'DRI', 'DVA', 'DE', 'DAL', 'XRAY', 'DVN', 'FANG', 'DLR', 'DFS', 'DISCA', 'DISCK', 'DISH', 'DG', 'DLTR', 'D', 'DOV', 'DWDP', 'DTE', 'DRE', 'DUK', 'DXC', 'ETFC', 'EMN', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'EMR', 'ETR', 'EOG', 'EFX', 'EQIX', 'EQR', 'ESS', 'EL', 'EVRG', 'ES', 'RE', 'EXC', 'EXPE', 'EXPD', 'EXR', 'XOM', 'FFIV', 'FB', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FE', 'FRC', 'FISV', 'FLT', 'FLIR', 'FLS', 'FLR', 'FMC', 'FL', 'F', 'FTNT', 'FTV', 'FBHS', 'BEN', 'FCX', 'GPS', 'GRMN', 'IT', 'GD', 'GE', 'GIS', 'GM', 'GPC', 'GILD', 'GPN', 'GS', 'GWW', 'HAL', 'HBI', 'HOG', 'HRS', 'HIG', 'HAS', 'HCA', 'HCP', 'HP', 'HSIC', 'HSY', 'HES', 'HPE', 'HLT', 'HFC', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HPQ', 'HUM', 'HBAN', 'HII', 'IDXX', 'INFO', 'ITW', 'ILMN', 'IR', 'INTC', 'ICE', 'IBM', 'INCY', 'IP', 'IPG', 'IFF', 'INTU', 'ISRG', 'IVZ', 'IPGP', 'IQV', 'IRM', 'JKHY', 'JEC', 'JBHT', 'JEF', 'SJM', 'JNJ', 'JCI', 'JPM', 'JNPR', 'KSU', 'K', 'KEY', 'KEYS', 'KMB', 'KIM', 'KMI', 'KLAC', 'KSS', 'KHC', 'KR', 'LB', 'LLL', 'LH', 'LRCX', 'LW', 'LEG', 'LEN', 'LLY', 'LNC', 'LIN', 'LKQ', 'LMT', 'L', 'LOW', 'LYB', 'MTB', 'MAC', 'M', 'MRO', 'MPC', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MAT', 'MKC', 'MXIM', 'MCD', 'MCK', 'MDT', 'MRK', 'MET', 'MTD', 'MGM', 'MCHP', 'MU', 'MSFT', 'MAA', 'MHK', 'TAP', 'MDLZ', 'MNST', 'MCO', 'MS', 'MOS', 'MSI', 'MSCI', 'MYL', 'NDAQ', 'NOV', 'NKTR', 'NTAP', 'NFLX', 'NWL', 'NEM', 'NWSA', 'NWS', 'NEE', 'NLSN', 'NKE', 'NI', 'NBL', 'JWN', 'NSC', 'NTRS', 'NOC', 'NCLH', 'NRG', 'NUE', 'NVDA', 'ORLY', 'OXY', 'OMC', 'OKE', 'ORCL', 'PCAR', 'PKG', 'PH', 'PAYX', 'PYPL', 'PNR', 'PBCT', 'PEP', 'PKI', 'PRGO', 'PFE', 'PM', 'PSX', 'PNW', 'PXD', 'PNC', 'RL', 'PPG', 'PPL', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PEG', 'PSA', 'PHM', 'PVH', 'QRVO', 'PWR', 'QCOM', 'DGX', 'RJF', 'RTN', 'O', 'RHT', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RHI', 'ROK', 'ROL', 'ROP', 'ROST', 'RCL', 'CRM', 'SBAC', 'SLB', 'STX', 'SEE', 'SRE', 'SHW', 'SPG', 'SWKS', 'SLG', 'SNA', 'SO', 'LUV', 'SPGI', 'SWK', 'SBUX', 'STT', 'SYK', 'STI', 'SIVB', 'SYMC', 'SYF', 'SNPS', 'SYY', 'TROW', 'TTWO', 'TPR', 'TGT', 'TEL', 'FTI', 'TFX', 'TXN', 'TXT', 'TMO', 'TIF', 'TWTR', 'TJX', 'TMK', 'TSS', 'TSCO', 'TDG', 'TRV', 'TRIP', 'FOXA', 'FOX', 'TSN', 'UDR', 'ULTA', 'USB', 'UAA', 'UA', 'UNP', 'UAL', 'UNH', 'UPS', 'URI', 'UTX', 'UHS', 'UNM', 'VFC', 'VLO', 'VAR', 'VTR', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VIAB', 'V', 'VNO', 'VMC', 'WAB', 'WMT', 'WBA', 'DIS', 'WM', 'WAT', 'WEC', 'WCG', 'WFC', 'WELL', 'WDC', 'WU', 'WRK', 'WY', 'WHR', 'WMB', 'WLTW', 'WYNN', 'XEL', 'XRX', 'XLNX', 'XYL', 'YUM', 'ZBH', 'ZION', 'ZTS']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MMM',\n",
       " 'ABT',\n",
       " 'ABBV',\n",
       " 'ABMD',\n",
       " 'ACN',\n",
       " 'ATVI',\n",
       " 'ADBE',\n",
       " 'AMD',\n",
       " 'AAP',\n",
       " 'AES',\n",
       " 'AMG',\n",
       " 'AFL',\n",
       " 'A',\n",
       " 'APD',\n",
       " 'AKAM',\n",
       " 'ALK',\n",
       " 'ALB',\n",
       " 'ARE',\n",
       " 'ALXN',\n",
       " 'ALGN',\n",
       " 'ALLE',\n",
       " 'AGN',\n",
       " 'ADS',\n",
       " 'LNT',\n",
       " 'ALL',\n",
       " 'GOOGL',\n",
       " 'GOOG',\n",
       " 'MO',\n",
       " 'AMZN',\n",
       " 'AEE',\n",
       " 'AAL',\n",
       " 'AEP',\n",
       " 'AXP',\n",
       " 'AIG',\n",
       " 'AMT',\n",
       " 'AWK',\n",
       " 'AMP',\n",
       " 'ABC',\n",
       " 'AME',\n",
       " 'AMGN',\n",
       " 'APH',\n",
       " 'APC',\n",
       " 'ADI',\n",
       " 'ANSS',\n",
       " 'ANTM',\n",
       " 'AON',\n",
       " 'AOS',\n",
       " 'APA',\n",
       " 'AIV',\n",
       " 'AAPL',\n",
       " 'AMAT',\n",
       " 'APTV',\n",
       " 'ADM',\n",
       " 'ARNC',\n",
       " 'ANET',\n",
       " 'AJG',\n",
       " 'AIZ',\n",
       " 'ATO',\n",
       " 'T',\n",
       " 'ADSK',\n",
       " 'ADP',\n",
       " 'AZO',\n",
       " 'AVB',\n",
       " 'AVY',\n",
       " 'BHGE',\n",
       " 'BLL',\n",
       " 'BAC',\n",
       " 'BK',\n",
       " 'BAX',\n",
       " 'BBT',\n",
       " 'BDX',\n",
       " 'BRK-B',\n",
       " 'BBY',\n",
       " 'BIIB',\n",
       " 'BLK',\n",
       " 'HRB',\n",
       " 'BA',\n",
       " 'BKNG',\n",
       " 'BWA',\n",
       " 'BXP',\n",
       " 'BSX',\n",
       " 'BHF',\n",
       " 'BMY',\n",
       " 'AVGO',\n",
       " 'BR',\n",
       " 'BF-B',\n",
       " 'CHRW',\n",
       " 'COG',\n",
       " 'CDNS',\n",
       " 'CPB',\n",
       " 'COF',\n",
       " 'CPRI',\n",
       " 'CAH',\n",
       " 'KMX',\n",
       " 'CCL',\n",
       " 'CAT',\n",
       " 'CBOE',\n",
       " 'CBRE',\n",
       " 'CBS',\n",
       " 'CE',\n",
       " 'CELG',\n",
       " 'CNC',\n",
       " 'CNP',\n",
       " 'CTL',\n",
       " 'CERN',\n",
       " 'CF',\n",
       " 'SCHW',\n",
       " 'CHTR',\n",
       " 'CVX',\n",
       " 'CMG',\n",
       " 'CB',\n",
       " 'CHD',\n",
       " 'CI',\n",
       " 'XEC',\n",
       " 'CINF',\n",
       " 'CTAS',\n",
       " 'CSCO',\n",
       " 'C',\n",
       " 'CFG',\n",
       " 'CTXS',\n",
       " 'CLX',\n",
       " 'CME',\n",
       " 'CMS',\n",
       " 'KO',\n",
       " 'CTSH',\n",
       " 'CL',\n",
       " 'CMCSA',\n",
       " 'CMA',\n",
       " 'CAG',\n",
       " 'CXO',\n",
       " 'COP',\n",
       " 'ED',\n",
       " 'STZ',\n",
       " 'COO',\n",
       " 'CPRT',\n",
       " 'GLW',\n",
       " 'COST',\n",
       " 'COTY',\n",
       " 'CCI',\n",
       " 'CSX',\n",
       " 'CMI',\n",
       " 'CVS',\n",
       " 'DHI',\n",
       " 'DHR',\n",
       " 'DRI',\n",
       " 'DVA',\n",
       " 'DE',\n",
       " 'DAL',\n",
       " 'XRAY',\n",
       " 'DVN',\n",
       " 'FANG',\n",
       " 'DLR',\n",
       " 'DFS',\n",
       " 'DISCA',\n",
       " 'DISCK',\n",
       " 'DISH',\n",
       " 'DG',\n",
       " 'DLTR',\n",
       " 'D',\n",
       " 'DOV',\n",
       " 'DWDP',\n",
       " 'DTE',\n",
       " 'DRE',\n",
       " 'DUK',\n",
       " 'DXC',\n",
       " 'ETFC',\n",
       " 'EMN',\n",
       " 'ETN',\n",
       " 'EBAY',\n",
       " 'ECL',\n",
       " 'EIX',\n",
       " 'EW',\n",
       " 'EA',\n",
       " 'EMR',\n",
       " 'ETR',\n",
       " 'EOG',\n",
       " 'EFX',\n",
       " 'EQIX',\n",
       " 'EQR',\n",
       " 'ESS',\n",
       " 'EL',\n",
       " 'EVRG',\n",
       " 'ES',\n",
       " 'RE',\n",
       " 'EXC',\n",
       " 'EXPE',\n",
       " 'EXPD',\n",
       " 'EXR',\n",
       " 'XOM',\n",
       " 'FFIV',\n",
       " 'FB',\n",
       " 'FAST',\n",
       " 'FRT',\n",
       " 'FDX',\n",
       " 'FIS',\n",
       " 'FITB',\n",
       " 'FE',\n",
       " 'FRC',\n",
       " 'FISV',\n",
       " 'FLT',\n",
       " 'FLIR',\n",
       " 'FLS',\n",
       " 'FLR',\n",
       " 'FMC',\n",
       " 'FL',\n",
       " 'F',\n",
       " 'FTNT',\n",
       " 'FTV',\n",
       " 'FBHS',\n",
       " 'BEN',\n",
       " 'FCX',\n",
       " 'GPS',\n",
       " 'GRMN',\n",
       " 'IT',\n",
       " 'GD',\n",
       " 'GE',\n",
       " 'GIS',\n",
       " 'GM',\n",
       " 'GPC',\n",
       " 'GILD',\n",
       " 'GPN',\n",
       " 'GS',\n",
       " 'GWW',\n",
       " 'HAL',\n",
       " 'HBI',\n",
       " 'HOG',\n",
       " 'HRS',\n",
       " 'HIG',\n",
       " 'HAS',\n",
       " 'HCA',\n",
       " 'HCP',\n",
       " 'HP',\n",
       " 'HSIC',\n",
       " 'HSY',\n",
       " 'HES',\n",
       " 'HPE',\n",
       " 'HLT',\n",
       " 'HFC',\n",
       " 'HOLX',\n",
       " 'HD',\n",
       " 'HON',\n",
       " 'HRL',\n",
       " 'HST',\n",
       " 'HPQ',\n",
       " 'HUM',\n",
       " 'HBAN',\n",
       " 'HII',\n",
       " 'IDXX',\n",
       " 'INFO',\n",
       " 'ITW',\n",
       " 'ILMN',\n",
       " 'IR',\n",
       " 'INTC',\n",
       " 'ICE',\n",
       " 'IBM',\n",
       " 'INCY',\n",
       " 'IP',\n",
       " 'IPG',\n",
       " 'IFF',\n",
       " 'INTU',\n",
       " 'ISRG',\n",
       " 'IVZ',\n",
       " 'IPGP',\n",
       " 'IQV',\n",
       " 'IRM',\n",
       " 'JKHY',\n",
       " 'JEC',\n",
       " 'JBHT',\n",
       " 'JEF',\n",
       " 'SJM',\n",
       " 'JNJ',\n",
       " 'JCI',\n",
       " 'JPM',\n",
       " 'JNPR',\n",
       " 'KSU',\n",
       " 'K',\n",
       " 'KEY',\n",
       " 'KEYS',\n",
       " 'KMB',\n",
       " 'KIM',\n",
       " 'KMI',\n",
       " 'KLAC',\n",
       " 'KSS',\n",
       " 'KHC',\n",
       " 'KR',\n",
       " 'LB',\n",
       " 'LLL',\n",
       " 'LH',\n",
       " 'LRCX',\n",
       " 'LW',\n",
       " 'LEG',\n",
       " 'LEN',\n",
       " 'LLY',\n",
       " 'LNC',\n",
       " 'LIN',\n",
       " 'LKQ',\n",
       " 'LMT',\n",
       " 'L',\n",
       " 'LOW',\n",
       " 'LYB',\n",
       " 'MTB',\n",
       " 'MAC',\n",
       " 'M',\n",
       " 'MRO',\n",
       " 'MPC',\n",
       " 'MAR',\n",
       " 'MMC',\n",
       " 'MLM',\n",
       " 'MAS',\n",
       " 'MA',\n",
       " 'MAT',\n",
       " 'MKC',\n",
       " 'MXIM',\n",
       " 'MCD',\n",
       " 'MCK',\n",
       " 'MDT',\n",
       " 'MRK',\n",
       " 'MET',\n",
       " 'MTD',\n",
       " 'MGM',\n",
       " 'MCHP',\n",
       " 'MU',\n",
       " 'MSFT',\n",
       " 'MAA',\n",
       " 'MHK',\n",
       " 'TAP',\n",
       " 'MDLZ',\n",
       " 'MNST',\n",
       " 'MCO',\n",
       " 'MS',\n",
       " 'MOS',\n",
       " 'MSI',\n",
       " 'MSCI',\n",
       " 'MYL',\n",
       " 'NDAQ',\n",
       " 'NOV',\n",
       " 'NKTR',\n",
       " 'NTAP',\n",
       " 'NFLX',\n",
       " 'NWL',\n",
       " 'NEM',\n",
       " 'NWSA',\n",
       " 'NWS',\n",
       " 'NEE',\n",
       " 'NLSN',\n",
       " 'NKE',\n",
       " 'NI',\n",
       " 'NBL',\n",
       " 'JWN',\n",
       " 'NSC',\n",
       " 'NTRS',\n",
       " 'NOC',\n",
       " 'NCLH',\n",
       " 'NRG',\n",
       " 'NUE',\n",
       " 'NVDA',\n",
       " 'ORLY',\n",
       " 'OXY',\n",
       " 'OMC',\n",
       " 'OKE',\n",
       " 'ORCL',\n",
       " 'PCAR',\n",
       " 'PKG',\n",
       " 'PH',\n",
       " 'PAYX',\n",
       " 'PYPL',\n",
       " 'PNR',\n",
       " 'PBCT',\n",
       " 'PEP',\n",
       " 'PKI',\n",
       " 'PRGO',\n",
       " 'PFE',\n",
       " 'PM',\n",
       " 'PSX',\n",
       " 'PNW',\n",
       " 'PXD',\n",
       " 'PNC',\n",
       " 'RL',\n",
       " 'PPG',\n",
       " 'PPL',\n",
       " 'PFG',\n",
       " 'PG',\n",
       " 'PGR',\n",
       " 'PLD',\n",
       " 'PRU',\n",
       " 'PEG',\n",
       " 'PSA',\n",
       " 'PHM',\n",
       " 'PVH',\n",
       " 'QRVO',\n",
       " 'PWR',\n",
       " 'QCOM',\n",
       " 'DGX',\n",
       " 'RJF',\n",
       " 'RTN',\n",
       " 'O',\n",
       " 'RHT',\n",
       " 'REG',\n",
       " 'REGN',\n",
       " 'RF',\n",
       " 'RSG',\n",
       " 'RMD',\n",
       " 'RHI',\n",
       " 'ROK',\n",
       " 'ROL',\n",
       " 'ROP',\n",
       " 'ROST',\n",
       " 'RCL',\n",
       " 'CRM',\n",
       " 'SBAC',\n",
       " 'SLB',\n",
       " 'STX',\n",
       " 'SEE',\n",
       " 'SRE',\n",
       " 'SHW',\n",
       " 'SPG',\n",
       " 'SWKS',\n",
       " 'SLG',\n",
       " 'SNA',\n",
       " 'SO',\n",
       " 'LUV',\n",
       " 'SPGI',\n",
       " 'SWK',\n",
       " 'SBUX',\n",
       " 'STT',\n",
       " 'SYK',\n",
       " 'STI',\n",
       " 'SIVB',\n",
       " 'SYMC',\n",
       " 'SYF',\n",
       " 'SNPS',\n",
       " 'SYY',\n",
       " 'TROW',\n",
       " 'TTWO',\n",
       " 'TPR',\n",
       " 'TGT',\n",
       " 'TEL',\n",
       " 'FTI',\n",
       " 'TFX',\n",
       " 'TXN',\n",
       " 'TXT',\n",
       " 'TMO',\n",
       " 'TIF',\n",
       " 'TWTR',\n",
       " 'TJX',\n",
       " 'TMK',\n",
       " 'TSS',\n",
       " 'TSCO',\n",
       " 'TDG',\n",
       " 'TRV',\n",
       " 'TRIP',\n",
       " 'FOXA',\n",
       " 'FOX',\n",
       " 'TSN',\n",
       " 'UDR',\n",
       " 'ULTA',\n",
       " 'USB',\n",
       " 'UAA',\n",
       " 'UA',\n",
       " 'UNP',\n",
       " 'UAL',\n",
       " 'UNH',\n",
       " 'UPS',\n",
       " 'URI',\n",
       " 'UTX',\n",
       " 'UHS',\n",
       " 'UNM',\n",
       " 'VFC',\n",
       " 'VLO',\n",
       " 'VAR',\n",
       " 'VTR',\n",
       " 'VRSN',\n",
       " 'VRSK',\n",
       " 'VZ',\n",
       " 'VRTX',\n",
       " 'VIAB',\n",
       " 'V',\n",
       " 'VNO',\n",
       " 'VMC',\n",
       " 'WAB',\n",
       " 'WMT',\n",
       " 'WBA',\n",
       " 'DIS',\n",
       " 'WM',\n",
       " 'WAT',\n",
       " 'WEC',\n",
       " 'WCG',\n",
       " 'WFC',\n",
       " 'WELL',\n",
       " 'WDC',\n",
       " 'WU',\n",
       " 'WRK',\n",
       " 'WY',\n",
       " 'WHR',\n",
       " 'WMB',\n",
       " 'WLTW',\n",
       " 'WYNN',\n",
       " 'XEL',\n",
       " 'XRX',\n",
       " 'XLNX',\n",
       " 'XYL',\n",
       " 'YUM',\n",
       " 'ZBH',\n",
       " 'ZION',\n",
       " 'ZTS']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
